# Chapter 7. 앙상블 학습과 랜덤 포레스트

## 7.4
### 7.4.2 특성 중요도
* 어떤 특성을 사용한 노드가 평균적으로 불순도를 얼마나 감소시키는지 확인
* = 가중치 평균 (각 노드의 가중치는 연관된 훈련 샘플 수와 같다)
* 특성별 (현재 노드의 샘플 비율 x 불순도) - (왼쪽 자식 노드의 샘플 비율 x 불순도) - (오른쪽 자식 노드의 샘플 비율  불순도)
* 특성 중요도의 합이 1이 되도록 전체 합으로 나누어 정규화.
* 각 결정 트리의 특성 중요도를 모두 계산하여 더한 후 트리 수로 나눈다.
* 어떤 특성이 중요한지 빠르게 확인할 수 있어 편리

## 7.5 부스팅
* 약한 학습기 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법
## 7.5.1 에이다부스트 
* 과소적합했던 훈련 샘플의 가중치를 더 높이는 것
* 새로운 예측기는 학습하기 어려운 샘플에 점점 더 맞춰지게 된다
* 경사 하강법은 비용 함수를 최소화 하기 위함 vs 에이다부스트는 점차 좋아지도록 
* 이전 예측기가 훈련되고 평가된 후 학습될 수 있기 때문에 병렬화/분할 불가능
